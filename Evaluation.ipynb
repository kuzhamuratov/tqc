{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from tqc import structures, DEVICE\n",
    "from tqc.trainer import Trainer\n",
    "from tqc.structures import Actor, Critic, RescaleAction\n",
    "from tqc.functions import eval_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[-0.  1.] or [0. 0.] is all 0s; this may be normal during initialization.\n"
     ]
    }
   ],
   "source": [
    "env_name = 'DKittyOrientRandomDynamics-v0'\n",
    "eval_env = gym.make(env_name).unwrapped\n",
    "eval_env = RescaleAction(eval_env, -1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = eval_env.observation_space.shape[0]\n",
    "action_dim = eval_env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda')\n",
    "actor = Actor(state_dim, action_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.load_state_dict(torch.load(\"./models/_DKittyOrientRandomDynamics-v0_0_actor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_policy(policy, eval_env, max_episode_steps, eval_episodes=10):\n",
    "    policy.eval()\n",
    "    avg_reward = 0.\n",
    "    for _ in range(eval_episodes):\n",
    "        state, done = eval_env.reset(), False\n",
    "        t = 0\n",
    "        while not done and t < max_episode_steps:\n",
    "            eval_env.render()\n",
    "            action = policy.select_action(state)\n",
    "            state, reward, done, _ = eval_env.step(action)\n",
    "            avg_reward += reward\n",
    "            t += 1\n",
    "    avg_reward /= eval_episodes\n",
    "    policy.train()\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    }
   ],
   "source": [
    "EPISODE_LENGTH = 160\n",
    "evaluations = []\n",
    "evaluations.append(eval_policy(actor, eval_env, EPISODE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2414.263986388017]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
